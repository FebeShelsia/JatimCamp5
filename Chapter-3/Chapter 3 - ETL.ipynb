{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL (Extract, Transform, Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract is refers to pulling the source data from the original database or data source. With ETL, the data goes into a temporary staging area. With ELT it goes immediately into a data lake storage system.\n",
    "\n",
    "- Transform is refers to the process of changing the structure of the information, so it integrates with the target data system and the rest of the data in that system.\n",
    "\n",
    "- Load is refers to the process of depositing the information into a data storage system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL VS ELT ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ```Tidak perlu bingung dengan istilahnya, ini teknik yang sama namun berbeda urutan```\n",
    "\n",
    "- ETL kita melakukan transformasi pada database staging atau python\n",
    "- ELT kita melakukan transformasi pada target database ( data warehouse )\n",
    "> contohnya ELT biasanya adalah data lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keuntungan ETL\n",
    "\n",
    "> ETL provides a more secure way to perform these transformations because it transforms the data before putting it into the data warehouse. In contrast, ELT requires you to upload the sensitive data first. That causes it to show up in logs where SysAdmins can access to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will only use pandas as a package that help us to solve all ETL problem\n",
    "\n",
    "> Why pandas ? Because it's so powerful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. EXTRACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### from open API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN API\n",
    "response = requests.get(\"https://hacker-news.firebaseio.com/v0/item/16222426.json\")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = pd.DataFrame(data_json, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW WE ARE USING REAL CASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- open folder Chapter-3 on JatimCamp5, then follow the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "# If there is no SQLachemy\n",
    "# pip install SQLAlchemy\n",
    "\n",
    "from Dependencies import credential_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- connect to production jatimcamp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.\n",
    "                                               format(credential_db.db_jatimcamp5_username, \n",
    "                                                      credential_db.db_jatimcamp5_password, \n",
    "                                                      credential_db.db_jatimcamp5_host, \n",
    "                                                      credential_db.db_jatimcamp5_name))\n",
    "\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check whether connect or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_table = \"\"\"show tables;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_table = pd.read_sql(query_table,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_listings = \"\"\"select * from listings\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings = pd.read_sql(query_listings, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to get another data from production, then we move to next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TRANSFORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I want do somes tranformation on this LISTING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### select columns that choosen, we can use drop function or just select column that we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings.drop(['listing_url',\n",
    "                       'thumbnail_url','medium_url',\n",
    "                       'xl_picture_url','host_thumbnail_url',\n",
    "                       'picture_url'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Edit column with UPPERCASE letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['country'] = df_data_listings['country'].apply(lambda x: x.upper())\n",
    "\n",
    "# OR\n",
    "\"\"\"\n",
    " df_data_listings['country'] = df_data_listings['country'].str.upper()\n",
    "\"\"\"\n",
    "\n",
    "df_data_listings['country'].tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### change price to IDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['price'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['price'] = df_data_listings['price'].apply(lambda x: x.lstrip('$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['price'] = df_data_listings['price'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['price_in_IDR'] = df_data_listings['price'] * 14700 # 14700 ( USD to IDR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['price_in_IDR'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### change dtype date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['last_review'] = pd.to_datetime(df_data_listings['last_review'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['last_review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings['last_review'] == '2016-09-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_listings[df_data_listings['last_review'] > '2016-08-01'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I want do somes tranformation on this REVIEWS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### find language in comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_reviews = \"\"\"select * from reviews\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_reviews = pd.read_sql(query_reviews, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSTALL langdetect first\n",
    "# !pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_reviews['comments_langdect'] = df_data_reviews['comments'].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Filter comment non English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_reviews[df_data_reviews['comments_langdect'] != 'en'].head() \n",
    "\n",
    "# it is not store into variable, so it is just works on this cell only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_reviews_non_eng = df_data_reviews[df_data_reviews['comments_langdect'] != 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_reviews_non_eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I want do somes tranformation on this CALENDARS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_calendars = \"\"\"select * from calendars\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_calendars = pd.read_sql(query_calendars, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_calendars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_calendars.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Remove null value from records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_calendars.dropna()\n",
    "\n",
    "# it is not store into variable, so it is just works on this cell only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_calendars_clean = df_data_calendars.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_calendars_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. LOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process that insert new data into storage ( we call it here DWH )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Why we use sqlachemy not pymysql ? Pandas require sqlachemy to connect with database, so we need it ```\n",
    "\n",
    "- Here documentation from pandas\n",
    "\n",
    "Using SQLAlchemy makes it possible to use any DB supported by that library. Legacy support is provided for sqlite3.Connection objects. The user is responsible for engine disposal and connection closure for the SQLAlchemy connectable See here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_dwh = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.\n",
    "                                               format(credential_db.db_jatimcamp5_DWH_username, \n",
    "                                                      credential_db.db_jatimcamp5_DWH_password, \n",
    "                                                      credential_db.db_jatimcamp5_DWH_host, \n",
    "                                                      credential_db.db_jatimcamp5_DWH_name))\n",
    "\n",
    "conn_dwh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### push clean calender into Datawarehouse (DWH) to provide data team "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_calendars_clean.to_sql(con=conn_dwh, name='calendars', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to check the data ? we can use IDE database ( such as dbeaver, navicat, etc ) \n",
    "\n",
    "#### OR we can query from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cal = 'select * from calendars limit 10'\n",
    "\n",
    "df_cal_dwh = pd.read_sql_query(query_cal, conn_dwh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal_dwh.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal_dwh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```Why do we load new data into new database ( jatimcamp5_dwh ) not in jatimcamp5 ?```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
